{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3-C_DN9BN-Pa"
   },
   "source": [
    "# **Minerando Dados - A maior comunidade de Data Science do Brasil**\n",
    "www.minerandodados.com.br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OkEHVK1IN-Pb"
   },
   "source": [
    "## **An√°lise de Sentimentos usando Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxOmgb7BN-Pc"
   },
   "source": [
    "* Criando modelos para an√°lise de sentimentos de tweets\n",
    "* Teste com Modelo usando tag de nega√ß√µes\n",
    "* Teste com Modelo usando Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9e_mycZN-Pd"
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y2qP6WFxN-Pg"
   },
   "source": [
    "**Ler arquivo de dados e conta a quantidade de linhas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = open('tweets.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_lista(arquivo):\n",
    "    lista = []\n",
    "    \n",
    "    linha = arquivo.readline().strip()\n",
    "    while linha != \"\":\n",
    "        if (linha != \"\\n\"):\n",
    "            tweet = json.loads(linha)\n",
    "            created_at = tweet[\"created_at\"]\n",
    "            id_str = tweet[\"id_str\"]\n",
    "            text = tweet[\"text\"]\n",
    "            \n",
    "            objeto = {\"created_at\":created_at, \"id_str\":id_str, \"text\":text}\n",
    "            \n",
    "            lista.append(objeto)\n",
    "        linha = arquivo.readline()\n",
    "        \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = cria_lista(arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'created_at': 'Tue Sep 10 13:52:02 +0000 2019', 'id_str': '1171421071708426240', 'text': 'ADEUS NETFLIX COM SEU CATALOGO DE FILMES LIXOSO'}, {'created_at': 'Tue Sep 10 13:52:04 +0000 2019', 'id_str': '1171421083322527744', 'text': 'Eu j√° tinha o Prime Video, alterei pra assinatura do Prime que vai sair mais barata e com muito mais benef√≠cios e o‚Ä¶ https://t.co/xkhWbqnt70'}, {'created_at': 'Tue Sep 10 13:52:04 +0000 2019', 'id_str': '1171421083620249601', 'text': 'RT @HLTCO: Sky Sports minimum cost: ¬£40 per month\\n\\nBT Sport minimum cost: ¬£30 pm\\n\\nPremier Sports cost: ¬£11.99 pm\\n\\nAmazon Prime cost: ¬£7.99‚Ä¶'}, {'created_at': 'Tue Sep 10 13:52:06 +0000 2019', 'id_str': '1171421088389062659', 'text': 'RT @bonjurliana: indo assinar o amazon prime https://t.co/wTWS36Wvoa'}, {'created_at': 'Tue Sep 10 13:52:08 +0000 2019', 'id_str': '1171421096631046144', 'text': 'Amazon prime por 10 conto com o prime v√≠deo, twitch prime e o servi√ßo de m√∫sica era tudo que eu precisava'}, {'created_at': 'Tue Sep 10 13:52:08 +0000 2019', 'id_str': '1171421099722252288', 'text': 'RT @milapellicer: Sobre o Amazon Prime no BR: \\n- o valor t√° lindo\\n- o servi√ßo √© √≥timo \\n- o cat√°logo de filmes √© recheado, as s√©ries exclusi‚Ä¶'}, {'created_at': 'Tue Sep 10 13:52:09 +0000 2019', 'id_str': '1171421101424988160', 'text': 'RT @TOEI_PR: Âêõ„ÅÆ„Éí„Éº„É≠„Éº„ÅØË™∞„Å†ÔºÅÔºü\\n\\n50ÔΩû90Âπ¥‰ª£„ÅÆÊáê„Åã„Åó„ÅÆÁâπÊíÆ‰ΩúÂìÅ„ÇíÊèê‰æõ„Åô„Çã„Äå„Éû„Ç§‚òÖ„Éí„Éº„É≠„Éº„Äç„ÅåAmazon Prime Video„ÉÅ„É£„É≥„Éç„É´„Å´„Å¶Êú¨Êó•„Çà„Çä„Çµ„Éº„Éì„ÇπÈñãÂßãüåü\\n#‰ªÆÈù¢„É©„Ç§„ÉÄ„Éº #„Çπ„Éº„Éë„ÉºÊà¶Èöä „É°„Çø„É´„Éí„Éº„É≠„Éº„ÄÅ„É≠„Éú„ÉÉ„Éà„Ç¢„Éã„É°„Å™„Å©„ÇíË¶ãÊîæÈ°å„Åß„ÅäÊ•Ω„Åó„Åø„Åè„Å†„Åï‚Ä¶'}, {'created_at': 'Tue Sep 10 13:52:09 +0000 2019', 'id_str': '1171421102100373505', 'text': 'RT @HLTCO: Sky Sports minimum cost: ¬£40 per month\\n\\nBT Sport minimum cost: ¬£30 pm\\n\\nPremier Sports cost: ¬£11.99 pm\\n\\nAmazon Prime cost: ¬£7.99‚Ä¶'}, {'created_at': 'Tue Sep 10 13:52:10 +0000 2019', 'id_str': '1171421105069920256', 'text': 'Amazon Prime chegou pra acabar com aquele discurso da Dilma de transformar os Correios na Amazon\\n\\nAmazon t√° muito melhor!'}, {'created_at': 'Tue Sep 10 13:52:11 +0000 2019', 'id_str': '1171421111936069633', 'text': 'Obrigado capitalismo opressor'}]\n"
     ]
    }
   ],
   "source": [
    "print(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Tue Sep 10 13:52:04 +0000 2019',\n",
       " 'id_str': '1171421083620249601',\n",
       " 'text': 'RT @HLTCO: Sky Sports minimum cost: ¬£40 per month\\n\\nBT Sport minimum cost: ¬£30 pm\\n\\nPremier Sports cost: ¬£11.99 pm\\n\\nAmazon Prime cost: ¬£7.99‚Ä¶'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_arquivo_csv(lista):\n",
    "    arquivo = open('tweets.csv', 'w', encoding='utf-8')\n",
    "    lista_chave = []\n",
    "    \n",
    "    #arquivo.write('id,')\n",
    "        \n",
    "    for chave in lista[0]:\n",
    "        lista_chave.append(chave)\n",
    "            \n",
    "    for pos in range(len(lista_chave)):\n",
    "        if pos == len(lista_chave)-1:\n",
    "            arquivo.write(lista_chave[pos] + '\\n')\n",
    "        else:\n",
    "            arquivo.write(lista_chave[pos] + ',')\n",
    "    \n",
    "    for dic in lista:\n",
    "        for pos in range(len(lista_chave)):\n",
    "            aux = dic[lista_chave[pos]]\n",
    "            if lista_chave[pos] == 'text':\n",
    "                aux = '\"' + dic[lista_chave[pos]] + '\"'\n",
    "                \n",
    "            if pos == len(lista_chave)-1:\n",
    "                arquivo.write(aux + '\\n')\n",
    "            else:\n",
    "                arquivo.write(aux + ',')\n",
    "        \n",
    "    arquivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "cria_arquivo_csv(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 911,
     "status": "error",
     "timestamp": 1541680897006,
     "user": {
      "displayName": "Rodrigo Santana Ferreira",
      "photoUrl": "https://lh5.googleusercontent.com/-w5AmPcUma78/AAAAAAAAAAI/AAAAAAAAAPw/2VfgXe2k7sI/s64/photo.jpg",
      "userId": "14710330936720624047"
     },
     "user_tz": 120
    },
    "id": "4slTJKvhN-Pg",
    "outputId": "5a0fbf25-492c-4c06-fdec-30fb0984bf3c"
   },
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('tweets.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J8_5WdPjN-Pj"
   },
   "source": [
    "**Exibe as 50 primeiras lihas de tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QI0jMKeN-Pk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Tue Sep 10 13:52:02 +0000 2019</td>\n",
       "      <td>1171421071708426240</td>\n",
       "      <td>ADEUS NETFLIX COM SEU CATALOGO DE FILMES LIXOSO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Tue Sep 10 13:52:04 +0000 2019</td>\n",
       "      <td>1171421083322527744</td>\n",
       "      <td>Eu j√° tinha o Prime Video, alterei pra assinat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Tue Sep 10 13:52:04 +0000 2019</td>\n",
       "      <td>1171421083620249601</td>\n",
       "      <td>RT @HLTCO: Sky Sports minimum cost: ¬£40 per mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Tue Sep 10 13:52:06 +0000 2019</td>\n",
       "      <td>1171421088389062659</td>\n",
       "      <td>RT @bonjurliana: indo assinar o amazon prime h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Tue Sep 10 13:52:08 +0000 2019</td>\n",
       "      <td>1171421096631046144</td>\n",
       "      <td>Amazon prime por 10 conto com o prime v√≠deo, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Tue Sep 10 13:52:08 +0000 2019</td>\n",
       "      <td>1171421099722252288</td>\n",
       "      <td>RT @milapellicer: Sobre o Amazon Prime no BR: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Tue Sep 10 13:52:09 +0000 2019</td>\n",
       "      <td>1171421101424988160</td>\n",
       "      <td>RT @TOEI_PR: Âêõ„ÅÆ„Éí„Éº„É≠„Éº„ÅØË™∞„Å†ÔºÅÔºü\\r\\n\\r\\n50ÔΩû90Âπ¥‰ª£„ÅÆÊáê„Åã„Åó„ÅÆÁâπÊíÆ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Tue Sep 10 13:52:09 +0000 2019</td>\n",
       "      <td>1171421102100373505</td>\n",
       "      <td>RT @HLTCO: Sky Sports minimum cost: ¬£40 per mo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Tue Sep 10 13:52:10 +0000 2019</td>\n",
       "      <td>1171421105069920256</td>\n",
       "      <td>Amazon Prime chegou pra acabar com aquele disc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>Tue Sep 10 13:52:11 +0000 2019</td>\n",
       "      <td>1171421111936069633</td>\n",
       "      <td>Obrigado capitalismo opressor</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       created_at               id_str  \\\n",
       "0  Tue Sep 10 13:52:02 +0000 2019  1171421071708426240   \n",
       "1  Tue Sep 10 13:52:04 +0000 2019  1171421083322527744   \n",
       "2  Tue Sep 10 13:52:04 +0000 2019  1171421083620249601   \n",
       "3  Tue Sep 10 13:52:06 +0000 2019  1171421088389062659   \n",
       "4  Tue Sep 10 13:52:08 +0000 2019  1171421096631046144   \n",
       "5  Tue Sep 10 13:52:08 +0000 2019  1171421099722252288   \n",
       "6  Tue Sep 10 13:52:09 +0000 2019  1171421101424988160   \n",
       "7  Tue Sep 10 13:52:09 +0000 2019  1171421102100373505   \n",
       "8  Tue Sep 10 13:52:10 +0000 2019  1171421105069920256   \n",
       "9  Tue Sep 10 13:52:11 +0000 2019  1171421111936069633   \n",
       "\n",
       "                                                text  \n",
       "0    ADEUS NETFLIX COM SEU CATALOGO DE FILMES LIXOSO  \n",
       "1  Eu j√° tinha o Prime Video, alterei pra assinat...  \n",
       "2  RT @HLTCO: Sky Sports minimum cost: ¬£40 per mo...  \n",
       "3  RT @bonjurliana: indo assinar o amazon prime h...  \n",
       "4  Amazon prime por 10 conto com o prime v√≠deo, t...  \n",
       "5  RT @milapellicer: Sobre o Amazon Prime no BR: ...  \n",
       "6  RT @TOEI_PR: Âêõ„ÅÆ„Éí„Éº„É≠„Éº„ÅØË™∞„Å†ÔºÅÔºü\\r\\n\\r\\n50ÔΩû90Âπ¥‰ª£„ÅÆÊáê„Åã„Åó„ÅÆÁâπÊíÆ...  \n",
       "7  RT @HLTCO: Sky Sports minimum cost: ¬£40 per mo...  \n",
       "8  Amazon Prime chegou pra acabar com aquele disc...  \n",
       "9                      Obrigado capitalismo opressor  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y1ciRVrDN-Pl"
   },
   "source": [
    "**Conta a quantidade de linhas de tweets neutros, positivos e negativos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mD7m9FBFN-Pm"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Classificacao'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-88-220a66838494>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClassificacao\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Neutro'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\maluf\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Classificacao'"
     ]
    }
   ],
   "source": [
    "dataset[dataset.Classificacao=='Neutro'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pd1bopmPN-Po"
   },
   "outputs": [],
   "source": [
    "dataset[dataset.Classificacao=='Positivo'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BbQDdx6fN-Pr"
   },
   "outputs": [],
   "source": [
    "dataset[dataset.Classificacao=='Negativo'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkZ7gTeJN-Pt"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'Classificacao'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-89-9655968ea7a7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'matplotlib'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inline'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mClassificacao\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkind\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'bar'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\maluf\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   5177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5179\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5180\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5181\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'Classificacao'"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "dataset.Classificacao.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCDmdHipN-Pv"
   },
   "outputs": [],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJFE0rWAN-Py"
   },
   "source": [
    "## Pre-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvrKfzJQN-Pz"
   },
   "source": [
    "* Remove linhas duplicadas na base de dados\n",
    "    - Problema na coleta dos dados.\n",
    "* Remove Stopwords\n",
    "* Faz Stemming nos dados\n",
    "* Remove caracteres indesejados como links, pontua√ß√£o etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iiIbvZbwN-P0"
   },
   "outputs": [],
   "source": [
    "dataset.drop_duplicates(['text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9AJh2pkEN-P1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.text.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Coh0XgGqN-P4"
   },
   "source": [
    "## ** Separando tweets e suas Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nMwzYhDFN-P4"
   },
   "outputs": [],
   "source": [
    "tweets = dataset['text']\n",
    "#classes = dataset['Classificacao']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y51tqO69N-P6"
   },
   "source": [
    "** Instala bibliotecas e baixa a base de dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mB2zdiTZN-P6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MaluF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\MaluF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping stemmers\\rslp.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7bAQswo_N-P8"
   },
   "source": [
    "**Fun√ß√µes de Pre-processamento de dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6VISYmqMN-P9"
   },
   "outputs": [],
   "source": [
    "def RemoveStopWords(instancia):\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1R52LDb2N-QB"
   },
   "outputs": [],
   "source": [
    "def Stemming(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    palavras = []\n",
    "    for w in instancia.split():\n",
    "        palavras.append(stemmer.stem(w))\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s1L3Kfr-N-QE"
   },
   "outputs": [],
   "source": [
    "def Limpeza_dados(instancia):\n",
    "    # remove links, pontos, virgulas,ponto e virgulas dos tweets\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    return (instancia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lusLFKwZN-QI"
   },
   "source": [
    "** Entenda como funciona cada fun√ß√£o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDtlMpUmN-QI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Eu gosto partido, votaria novamente nesse governante!'"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RemoveStopWords('Eu n√£o gosto do partido, e tamb√©m n√£o votaria novamente nesse governante!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnrJKtZFN-QK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'eu n√£o gost do partido, e tamb√©m n√£o vot nov ness governante!'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Stemming('Eu n√£o gosto do partido, e tamb√©m n√£o votaria novamente nesse governante!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFrAgPI9N-QL"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'assita aqui o video do governador falando sobre a cemig   '"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Limpeza_dados('Assita aqui o video do Governador falando sobre a CEMIG https://www.uol.com.br :) ;)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFRbKWfFN-QO"
   },
   "source": [
    "** Aplica as 3 fun√ß√µes de Pre-processamento nos dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BAlu-RtDN-QP"
   },
   "outputs": [],
   "source": [
    "def Preprocessing(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    palavras = [stemmer.stem(i) for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))\n",
    "\n",
    "# Aplica a fun√ß√£o em todos os dados:\n",
    "tweets = [Preprocessing(i) for i in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpbDgdfEN-QR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'gost partido, vot nov ness govern assit vide aqu'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Preprocessing('Eu n√£o gosto do partido, e tamb√©m n√£o votaria novamente nesse governante. Assita o video aqui https:// :)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "created_at\n",
      "id_str\n",
      "text\n"
     ]
    }
   ],
   "source": [
    "for i in dataset:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Nr2nQYXN-QS"
   },
   "source": [
    "**Visualize os dados e veja como ficou ap√≥s o pr√©-processamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c04o1V3xN-QT"
   },
   "outputs": [],
   "source": [
    "tweets[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "0kqSnklmN-QV"
   },
   "source": [
    "## Criando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OuEc376oN-QV"
   },
   "source": [
    "**Instancia o objeto que faz a vetoriza√ß√£o dos dados de texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kPGn3G6N-QW"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL168-e0N-QY"
   },
   "source": [
    "**Aplica o vetorizador nos dados de texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z_OufE_5N-QY"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "type(freq_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GzHXr2TNN-Qa"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-106-47118a5c77b1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodelo\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMultinomialNB\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodelo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfreq_tweets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S-vF1aDAN-Qd"
   },
   "source": [
    "**Formato (Linhas, Colunas) da matriz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LNuDjTH6N-Qe"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 74)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R1ANkhjhN-Qg"
   },
   "source": [
    "**Matriz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g05OeGVCN-Qg"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 2, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 4, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 2, 1, 0, 0, 0, 0, 1, 2, 0,\n",
       "        0, 1, 1, 0, 1, 0, 0, 1, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 3, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "        0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
       "        0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_tweets.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MsWdPRkaN-Qj"
   },
   "source": [
    "** Testando o modelo com algumas inst√¢ncias simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oKswXL8TN-Qj"
   },
   "outputs": [],
   "source": [
    "# defina inst√¢ncias de teste dentro de uma lista\n",
    "testes = ['Esse governo est√° no in√≠cio, vamos ver o que vai dar',\n",
    "          'Estou muito feliz com o governo de Minas esse ano',\n",
    "          'O estado de Minas Gerais decretou calamidade financeira!!!',\n",
    "          'A seguran√ßa desse pa√≠s est√° deixando a desejar',\n",
    "          'O governador de Minas √© mais uma vez do PT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K5qgbrDPN-Qm"
   },
   "source": [
    "**Aplica a fun√ß√£o de Pr√©-processamento nos dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rbcyd6wN-Qm"
   },
   "outputs": [],
   "source": [
    "testes = [Preprocessing(i) for i in testes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vh-MK_RBN-Qo"
   },
   "outputs": [],
   "source": [
    "# Transforma os dados de teste em vetores de palavras.\n",
    "freq_testes = vectorizer.transform(testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rWwXiAsLN-Qp"
   },
   "outputs": [],
   "source": [
    "# Fazendo a classifica√ß√£o com o modelo treinado.\n",
    "for t, c in zip (testes,modelo.predict(freq_testes)):\n",
    "    print (t +\", \"+ c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URzT5h0pN-Qr"
   },
   "outputs": [],
   "source": [
    "# Probabilidades de cada classe\n",
    "print (modelo.classes_)\n",
    "modelo.predict_proba(freq_testes).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OjrcFuYNN-Qv"
   },
   "source": [
    "## ** Fun√ß√£o de Tags de Nega√ß√µes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hl7fpNi4N-Qw"
   },
   "source": [
    "* Acrescenta uma tag _NEG encontrada ap√≥s um 'n√£o'.\n",
    "* Objetivo √© dar mais peso para o modelo identificar uma invers√£o de sentimento da frase.\n",
    "* Exemplos: \n",
    "    - Eu gosto de cachorros, positivo.\n",
    "    - Eu **n√£o** gosto de cachorros, negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0uWFI7CN-Qw"
   },
   "outputs": [],
   "source": [
    "def marque_negacao(texto):\n",
    "    negacoes = ['n√£o','not']\n",
    "    negacao_detectada = False\n",
    "    resultado = []\n",
    "    palavras = texto.split()\n",
    "    for p in palavras:\n",
    "        p = p.lower()\n",
    "        if negacao_detectada == True:\n",
    "            p = p + '_NEG'\n",
    "        if p in negacoes:\n",
    "            negacao_detectada = True\n",
    "        resultado.append(p)\n",
    "    return (\" \".join(resultado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VnEGlbyQN-Q1"
   },
   "source": [
    "**Exemplos de utiliza√ß√£o da tag de nega√ß√µes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZZNWh2YN-Q1"
   },
   "outputs": [],
   "source": [
    "marque_negacao('Eu gosto do partido, votaria novamente nesse governante!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3XE8NMBN-Q3"
   },
   "outputs": [],
   "source": [
    "marque_negacao('Eu N√£o gosto do partido, e tamb√©m n√£o votaria novamente nesse governante!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuMo0NyzN-Q6"
   },
   "source": [
    "## **Criando modelos com Pipelines**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QV9ZaTo4N-Q7"
   },
   "source": [
    "* Pipelines s√£o interessantes para reduzir c√≥digo e automatizar fluxos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E0W5gpr2N-Q7"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OEqd6LpEN-Q-"
   },
   "outputs": [],
   "source": [
    "pipeline_simples = Pipeline([\n",
    "  ('counts', CountVectorizer()),\n",
    "  ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xx83-l2jN-RA"
   },
   "source": [
    "* Pipeline que atribui tag de negacoes nas palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QMja6f1_N-RA"
   },
   "outputs": [],
   "source": [
    "pipeline_negacoes = Pipeline([\n",
    "  ('counts', CountVectorizer(tokenizer=lambda text: marque_negacao(text))),\n",
    "  ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3s8IYnTqN-RB"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-1a34318aabc4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpipeline_simples\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline_simples.fit(tweets,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eEe_xi5RN-RF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('counts',\n",
       "  CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                  dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                  lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                  ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                  strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                  tokenizer=None, vocabulary=None)),\n",
       " ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_simples.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zFtrsfPLN-RG"
   },
   "source": [
    "* Gera o modelo de nega√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7qvoT9KN-RG"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-118-feb77cdb8d96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mpipeline_negacoes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "pipeline_negacoes.fit(tweets,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vb_16zLWN-RI"
   },
   "source": [
    "* Etapas do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxAXlTCZN-RI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('counts',\n",
       "  CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "                  dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "                  lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "                  ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "                  strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "                  tokenizer=<function <lambda> at 0x04C2E1E0>, vocabulary=None)),\n",
       " ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline_negacoes.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uOrdLbpN-RL"
   },
   "source": [
    "## Validando os Modelos com Valida√ß√£o Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "ZSO1TDjdN-RL"
   },
   "source": [
    "* Fazendo o cross validation do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdzCoSkdN-RM"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-120-414019d97a6b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresultados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_simples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "resultados = cross_val_predict(pipeline_simples, tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "6wrZIEfGN-RO"
   },
   "source": [
    "* Medindo a acur√°cia m√©dia do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsqVrFdtN-RO"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-121-aecdb42649ec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresultados\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "5D32i6aKN-RS"
   },
   "source": [
    "* Medidas de valida√ß√£o do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zxOQrd4N-RT"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-122-a0662bd66937>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0msentimento\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Positivo'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Negativo'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Neutro'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mresultados\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msentimento\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "sentimento=['Positivo','Negativo','Neutro']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKfnnvw4N-RU"
   },
   "source": [
    "* Matriz de confus√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsrSrom-N-RW"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-123-868070cef2d7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcrosstab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresultados\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrownames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Real'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolnames\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Predito'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmargins\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B0_8SCJ9N-RX"
   },
   "source": [
    "## **Modelo com a Tag de Nega√ß√µes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3l3iT9tN-RX"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-124-39dc63905672>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresultados\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpipeline_negacoes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'classes' is not defined"
     ]
    }
   ],
   "source": [
    "resultados = cross_val_predict(pipeline_negacoes, tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE_1SUj-N-RZ"
   },
   "source": [
    "* Medindo a acur√°cia m√©dia do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQOijDH7N-RZ"
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RAuDaRzrN-Rb"
   },
   "outputs": [],
   "source": [
    "sentimento=['Positivo','Negativo','Neutro']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "xdFPuGoEN-Rd"
   },
   "source": [
    "* Matriz de confus√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Ka8d4A9N-Rd"
   },
   "outputs": [],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjTqTnFiN-Rg"
   },
   "source": [
    "## ** Avaliando modelo com Bigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pnp_Q6SkN-Rh"
   },
   "outputs": [],
   "source": [
    "'eu gosto', 'gosto do' , 'do brasil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3P6z5RcXN-Ri"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQk6Y-cwN-Rk"
   },
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXjpvOjqN-Rl"
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9j4l-8Y3N-Rn"
   },
   "outputs": [],
   "source": [
    "sentimento=['Positivo','Negativo','Neutro']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0zTMXL2tN-Ro"
   },
   "outputs": [],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8WkzVgIN-Rp"
   },
   "source": [
    "## ** Considera√ß√µes Finais**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "su1YgnZ1N-Rp"
   },
   "source": [
    "* Considere aumentar a quantidade de dados de treino.\n",
    "\n",
    "* Pela sua simplicidade o Naive Bayes pode ser usado perfeitamente como um algoritmo de Baseline.\n",
    "\n",
    "* Considere alterar os par√¢metros do algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jL2x-FrIN-Rq"
   },
   "source": [
    "**www.minerandodados.com.br** - *A maior comunidade de Data Science do Brasil*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classifica√ß√£o_tweets.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
