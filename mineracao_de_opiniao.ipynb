{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importando bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install python-twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twitter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn import svm\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configurando api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando o arquivo de configuração\n",
    "with open('tokens.json') as f:\n",
    "    data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregando a API do Twitter, utilizando os dados do arquivo json\n",
    "api = twitter.Api(**data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testa se tudo está certo\n",
    "# Caso tiver alguma credencial errada, o resultado será:\n",
    "#twitter.error.TwitterError: [{'code': 32, 'message': 'Could not authenticate you.'}]\n",
    "\n",
    "print(api.VerifyCredentials())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A API do Twitter permite fazer diversos tipos de consultas. \n",
    "# Função que, a partir de uma lista de status, mostra o nome do usuário e o texto do twitter.\n",
    "\n",
    "def print_status(status_list):\n",
    "    for status in status_list:\n",
    "        print('(' + str(status.created_at) + ') ' + str(status.user.name) + ':' + str(status.text) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscando dados do twitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Busca por termos\n",
    "\n",
    "status_list = api.GetSearch(term=\"xiaomi\",\n",
    "                            lang='pt',\n",
    "                            count=100,\n",
    "                            result_type='mixed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando lista com os tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_tweet_list(status_list):\n",
    "    tweet_list = []\n",
    "    \n",
    "    for tweet in status_list:\n",
    "        tweet_list.append(tweet.text)\n",
    "    \n",
    "    return tweet_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printando elementos\n",
    "print_status(status_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(status_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_list = cria_tweet_list(status_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweet_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coloca os tweets da lista em um arquivo .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_arquivo_csv(lista):\n",
    "    arquivo = open('xiaomi.csv', 'w', encoding='utf-8')\n",
    "    \n",
    "    for pos_tweet in range(len(lista)):\n",
    "        arquivo.write('\"' + str(lista[pos_tweet]) + '\"')\n",
    "        arquivo.write('\\n')\n",
    "        \n",
    "    arquivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cria_arquivo_csv(tweet_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cria um data frame (depois dos dados extraidos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando data frame\n",
    "df = pd.read_csv('classificado_xiaomi.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweets</th>\n",
       "      <th>classes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Agr até eu quero um xiaomi</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>xiaomi= tudo pra mim. https://t.co/7lAvXTxa2J</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>RT @karnsteins: meu celular está 1 dia e 6 hor...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>@Juliano_Fleck Se procura aplicativo usa o Sma...</td>\n",
       "      <td>positivo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>@paginamemebro nn gosto da câmera do xiaomi</td>\n",
       "      <td>negativo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              tweets   classes\n",
       "0                         Agr até eu quero um xiaomi  positivo\n",
       "1      xiaomi= tudo pra mim. https://t.co/7lAvXTxa2J  positivo\n",
       "2  RT @karnsteins: meu celular está 1 dia e 6 hor...  positivo\n",
       "3  @Juliano_Fleck Se procura aplicativo usa o Sma...  positivo\n",
       "4        @paginamemebro nn gosto da câmera do xiaomi  negativo"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x12427570>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "df.classes.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positivo    50\n",
       "neutro      28\n",
       "negativo    22\n",
       "Name: classes, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.classes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweets.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove os tweets duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tweets.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = df['tweets']\n",
    "classes = df['classes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "print(len(tweets))\n",
    "print(len(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpeza dos dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\MaluF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package rslp to\n",
      "[nltk_data]     C:\\Users\\MaluF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package rslp is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\MaluF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\MaluF\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Para limpeza dos dados\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'tenhamos', 'aquela', 'sem', 'formos', 'terá', 'estiverem', 'pelas', 'fui', 'houve', 'não', 'das', 'pela', 'estes', 'estiver', 'terei', 'somos', 'à', 'hei', 'por', 'suas', 'lhes', 'também', 'do', 'eu', 'está', 'ela', 'houveram', 'foi', 'meu', 'foram', 'tenho', 'os', 'estas', 'seriam', 'tinha', 'tivermos', 'sou', 'nosso', 'estão', 'vos', 'houvemos', 'eles', 'qual', 'tive', 'minha', 'dele', 'esta', 'depois', 'houvessem', 'essas', 'e', 'houvéssemos', 'houveríamos', 'serão', 'deles', 'que', 'para', 'aqueles', 'tu', 'esteja', 'serei', 'seremos', 'tiveram', 'tivessem', 'tínhamos', 'ou', 'numa', 'teríamos', 'havemos', 'às', 'fomos', 'minhas', 'estava', 'estávamos', 'éramos', 'tivéssemos', 'num', 'terão', 'nossos', 'tenha', 'a', 'seus', 'me', 'uma', 'seria', 'fôssemos', 'só', 'estiveram', 'estivemos', 'temos', 'ao', 'há', 'é', 'tivesse', 'nossa', 'já', 'em', 'se', 'te', 'nós', 'tinham', 'este', 'elas', 'tuas', 'esteve', 'com', 'houverão', 'tua', 'esses', 'dos', 'houverem', 'de', 'eram', 'tém', 'sua', 'teria', 'tiverem', 'da', 'estivesse', 'vocês', 'como', 'essa', 'o', 'esse', 'isto', 'teve', 'no', 'estivermos', 'estive', 'fôramos', 'sejam', 'fora', 'hajamos', 'mais', 'estivéssemos', 'haja', 'seríamos', 'aos', 'seu', 'tivéramos', 'lhe', 'mas', 'ele', 'nem', 'muito', 'estou', 'estejamos', 'houveremos', 'sejamos', 'teremos', 'será', 'fossem', 'pelo', 'até', 'estejam', 'delas', 'estivessem', 'houvesse', 'mesmo', 'teus', 'teriam', 'nas', 'você', 'quem', 'houvéramos', 'houverei', 'tiver', 'tivera', 'as', 'quando', 'houver', 'são', 'estavam', 'forem', 'houvera', 'hão', 'seja', 'tem', 'pelos', 'houverá', 'houveriam', 'meus', 'tenham', 'um', 'aquele', 'houveria', 'fosse', 'teu', 'for', 'aquelas', 'nossas', 'na', 'dela', 'era', 'entre', 'aquilo', 'houvermos', 'estamos', 'estivera', 'estivéramos', 'tivemos', 'hajam', 'isso', 'nos'}\n"
     ]
    }
   ],
   "source": [
    "stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "print(stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocessing(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(',','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    stopwords.remove('não')\n",
    "    palavras = [stemmer.stem(i) for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "testes = [Preprocessing(i) for i in tweets]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TweetTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_tokenizer = TweetTokenizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vetorização - Bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instancia o objeto que faz a vectorização\n",
    "vectorizer = CountVectorizer(analyzer=\"word\", tokenizer=tweet_tokenizer.tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Aplica o vetorizador nos dados\n",
    "# Ajuste o modelo SVM de acordo com os dados de treinamento fornecidos.\n",
    "freq_tweets = vectorizer.fit_transform(testes)\n",
    "type(freq_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "print(len(testes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 444)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formato linha, coluna da matriz\n",
    "freq_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando o modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = svm.SVC(gamma='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "    decision_function_shape='ovr', degree=3, gamma='auto', kernel='rbf',\n",
       "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
       "    tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "modelo.fit(freq_tweets,classes)\n",
    "#passando os tweets vetorizados (x, y) e as classes\n",
    "#mostrando pro modelo como ele aprender como ele representa os sentimentos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 1]], dtype=int64)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq_tweets.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Criando modelos com Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipelines são interessantes para reduzir código e automatizar fluxos\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_svm_simples = Pipeline([\n",
    "  ('counts', CountVectorizer()),\n",
    "  ('classifier', svm.SVC(kernel='linear'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validando os Modelos com Validação Cruzada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\maluf\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 22 members, which is too few. The minimum number of members in any class cannot be less than n_splits=48.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "# Fazendo o cross validation do modelo\n",
    "resultados = cross_val_predict(pipeline_svm_simples, testes, classes, cv=48)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predito   negativo  neutro  positivo  All\n",
      "Real                                     \n",
      "negativo         7       3        12   22\n",
      "neutro           3      11        14   28\n",
      "positivo         2       4        43   49\n",
      "All             12      18        69   99\n"
     ]
    }
   ],
   "source": [
    "# Matriz de confusão\n",
    "print(pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6161616161616161"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Medindo a acurácia média do modelo\n",
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acuracia =  0.6161616161616161\n"
     ]
    }
   ],
   "source": [
    "acuracia = (7+11+43)/99\n",
    "print('acuracia = ', acuracia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    positivo       0.62      0.88      0.73        49\n",
      "    negativo       0.58      0.32      0.41        22\n",
      "      neutro       0.61      0.39      0.48        28\n",
      "\n",
      "    accuracy                           0.62        99\n",
      "   macro avg       0.61      0.53      0.54        99\n",
      "weighted avg       0.61      0.62      0.59        99\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Medidas de validação do modelo\n",
    "sentimento=['positivo','negativo','neutro']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
