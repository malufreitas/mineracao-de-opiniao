{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3-C_DN9BN-Pa"
   },
   "source": [
    "# **Minerando Dados - A maior comunidade de Data Science do Brasil**\n",
    "www.minerandodados.com.br"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OkEHVK1IN-Pb"
   },
   "source": [
    "## **An√°lise de Sentimentos usando Machine Learning**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sxOmgb7BN-Pc"
   },
   "source": [
    "* Criando modelos para an√°lise de sentimentos de tweets\n",
    "* Teste com Modelo usando tag de nega√ß√µes\n",
    "* Teste com Modelo usando Bigrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B9e_mycZN-Pd"
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import cross_val_predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y2qP6WFxN-Pg"
   },
   "source": [
    "**Ler arquivo de dados e conta a quantidade de linhas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "arquivo = open('tweets.txt', 'r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_lista(arquivo):\n",
    "    lista = []\n",
    "    \n",
    "    linha = arquivo.readline().strip()\n",
    "    while linha != \"\":\n",
    "        if (linha != \"\\n\"):\n",
    "            tweet = json.loads(linha)\n",
    "            created_at = tweet[\"created_at\"]\n",
    "            id_str = tweet[\"id_str\"]\n",
    "            text = tweet[\"text\"]\n",
    "            \n",
    "            objeto = {\"created_at\":created_at, \"id_str\":id_str, \"text\":text}\n",
    "            \n",
    "            lista.append(objeto)\n",
    "        linha = arquivo.readline()\n",
    "        \n",
    "    return lista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "lista = cria_lista(arquivo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'created_at': 'Tue Sep 10 13:52:02 +0000 2019', 'id_str': '1171421071708426240', 'text': 'ADEUS NETFLIX COM SEU CATALOGO DE FILMES LIXOSO'}, {'created_at': 'Tue Sep 10 13:52:04 +0000 2019', 'id_str': '1171421083322527744', 'text': 'Eu j√° tinha o Prime Video, alterei pra assinatura do Prime que vai sair mais barata e com muito mais benef√≠cios e o‚Ä¶ https://t.co/xkhWbqnt70'}, {'created_at': 'Tue Sep 10 13:52:04 +0000 2019', 'id_str': '1171421083620249601', 'text': 'RT @HLTCO: Sky Sports minimum cost: ¬£40 per month\\n\\nBT Sport minimum cost: ¬£30 pm\\n\\nPremier Sports cost: ¬£11.99 pm\\n\\nAmazon Prime cost: ¬£7.99‚Ä¶'}, {'created_at': 'Tue Sep 10 13:52:06 +0000 2019', 'id_str': '1171421088389062659', 'text': 'RT @bonjurliana: indo assinar o amazon prime https://t.co/wTWS36Wvoa'}, {'created_at': 'Tue Sep 10 13:52:08 +0000 2019', 'id_str': '1171421096631046144', 'text': 'Amazon prime por 10 conto com o prime v√≠deo, twitch prime e o servi√ßo de m√∫sica era tudo que eu precisava'}, {'created_at': 'Tue Sep 10 13:52:08 +0000 2019', 'id_str': '1171421099722252288', 'text': 'RT @milapellicer: Sobre o Amazon Prime no BR: \\n- o valor t√° lindo\\n- o servi√ßo √© √≥timo \\n- o cat√°logo de filmes √© recheado, as s√©ries exclusi‚Ä¶'}, {'created_at': 'Tue Sep 10 13:52:09 +0000 2019', 'id_str': '1171421101424988160', 'text': 'RT @TOEI_PR: Âêõ„ÅÆ„Éí„Éº„É≠„Éº„ÅØË™∞„Å†ÔºÅÔºü\\n\\n50ÔΩû90Âπ¥‰ª£„ÅÆÊáê„Åã„Åó„ÅÆÁâπÊíÆ‰ΩúÂìÅ„ÇíÊèê‰æõ„Åô„Çã„Äå„Éû„Ç§‚òÖ„Éí„Éº„É≠„Éº„Äç„ÅåAmazon Prime Video„ÉÅ„É£„É≥„Éç„É´„Å´„Å¶Êú¨Êó•„Çà„Çä„Çµ„Éº„Éì„ÇπÈñãÂßãüåü\\n#‰ªÆÈù¢„É©„Ç§„ÉÄ„Éº #„Çπ„Éº„Éë„ÉºÊà¶Èöä „É°„Çø„É´„Éí„Éº„É≠„Éº„ÄÅ„É≠„Éú„ÉÉ„Éà„Ç¢„Éã„É°„Å™„Å©„ÇíË¶ãÊîæÈ°å„Åß„ÅäÊ•Ω„Åó„Åø„Åè„Å†„Åï‚Ä¶'}, {'created_at': 'Tue Sep 10 13:52:09 +0000 2019', 'id_str': '1171421102100373505', 'text': 'RT @HLTCO: Sky Sports minimum cost: ¬£40 per month\\n\\nBT Sport minimum cost: ¬£30 pm\\n\\nPremier Sports cost: ¬£11.99 pm\\n\\nAmazon Prime cost: ¬£7.99‚Ä¶'}, {'created_at': 'Tue Sep 10 13:52:10 +0000 2019', 'id_str': '1171421105069920256', 'text': 'Amazon Prime chegou pra acabar com aquele discurso da Dilma de transformar os Correios na Amazon\\n\\nAmazon t√° muito melhor!'}, {'created_at': 'Tue Sep 10 13:52:11 +0000 2019', 'id_str': '1171421111936069633', 'text': 'Obrigado capitalismo opressor'}]\n"
     ]
    }
   ],
   "source": [
    "print(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'created_at': 'Tue Sep 10 13:52:04 +0000 2019',\n",
       " 'id_str': '1171421083620249601',\n",
       " 'text': 'RT @HLTCO: Sky Sports minimum cost: ¬£40 per month\\n\\nBT Sport minimum cost: ¬£30 pm\\n\\nPremier Sports cost: ¬£11.99 pm\\n\\nAmazon Prime cost: ¬£7.99‚Ä¶'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lista[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cria_arquivo_csv(lista):\n",
    "    arquivo = open('tweets.csv', 'w', encoding='utf-8')\n",
    "    lista_chave = []\n",
    "    \n",
    "    #arquivo.write('id,')\n",
    "        \n",
    "    for chave in lista[0]:\n",
    "        lista_chave.append(chave)\n",
    "            \n",
    "    for pos in range(len(lista_chave)):\n",
    "        if pos == len(lista_chave)-1:\n",
    "            arquivo.write(lista_chave[pos] + '\\n')\n",
    "        else:\n",
    "            arquivo.write(lista_chave[pos] + ',')\n",
    "    \n",
    "    for dic in lista:\n",
    "        for pos in range(len(lista_chave)):\n",
    "            aux = dic[lista_chave[pos]]\n",
    "            if lista_chave[pos] == 'text':\n",
    "                aux = '\"' + dic[lista_chave[pos]] + '\"'\n",
    "                \n",
    "            if pos == len(lista_chave)-1:\n",
    "                arquivo.write(aux + '\\n')\n",
    "            else:\n",
    "                arquivo.write(aux + ',')\n",
    "        \n",
    "    arquivo.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "cria_arquivo_csv(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 846
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 911,
     "status": "error",
     "timestamp": 1541680897006,
     "user": {
      "displayName": "Rodrigo Santana Ferreira",
      "photoUrl": "https://lh5.googleusercontent.com/-w5AmPcUma78/AAAAAAAAAAI/AAAAAAAAAPw/2VfgXe2k7sI/s64/photo.jpg",
      "userId": "14710330936720624047"
     },
     "user_tz": 120
    },
    "id": "4slTJKvhN-Pg",
    "outputId": "5a0fbf25-492c-4c06-fdec-30fb0984bf3c"
   },
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 3 fields in line 3, saw 4\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-82-51a2fb82b814>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdataset\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'tweets.csv'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\maluf\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    683\u001b[0m         )\n\u001b[0;32m    684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 685\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    686\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maluf\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    461\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    462\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 463\u001b[1;33m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    464\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    465\u001b[0m         \u001b[0mparser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maluf\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1152\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1153\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_integer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"nrows\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1154\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1155\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m         \u001b[1;31m# May alter columns / col_dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\maluf\\appdata\\local\\programs\\python\\python37-32\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   2057\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2058\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2059\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2060\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2061\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_first_chunk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_low_memory\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 3 fields in line 3, saw 4\n"
     ]
    }
   ],
   "source": [
    "dataset = pd.read_csv('tweets.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "J8_5WdPjN-Pj"
   },
   "source": [
    "**Exibe as 50 primeiras lihas de tweets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7QI0jMKeN-Pk"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id_str</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Tue Sep 10 13:52:02 +0000 2019</td>\n",
       "      <td>1171421071708426240</td>\n",
       "      <td>ADEUS NETFLIX COM SEU CATALOGO DE FILMES LIXOSO</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Tue Sep 10 13:52:04 +0000 2019</td>\n",
       "      <td>1171421083322527744</td>\n",
       "      <td>Eu j√° tinha o Prime Video</td>\n",
       "      <td>alterei pra assinatura do Prime que vai sair ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Tue Sep 10 13:52:04 +0000 2019</td>\n",
       "      <td>1171421083620249601</td>\n",
       "      <td>RT @HLTCO: Sky Sports minimum cost: ¬£40 per month</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>BT Sport minimum cost: ¬£30 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Premier Sports cost: ¬£11.99 pm</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>Amazon Prime cost: ¬£7.99‚Ä¶</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>Tue Sep 10 13:52:06 +0000 2019</td>\n",
       "      <td>1171421088389062659</td>\n",
       "      <td>RT @bonjurliana: indo assinar o amazon prime h...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>Tue Sep 10 13:52:08 +0000 2019</td>\n",
       "      <td>1171421096631046144</td>\n",
       "      <td>Amazon prime por 10 conto com o prime v√≠deo</td>\n",
       "      <td>twitch prime e o servi√ßo de m√∫sica era tudo q...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>Tue Sep 10 13:52:08 +0000 2019</td>\n",
       "      <td>1171421099722252288</td>\n",
       "      <td>RT @milapellicer: Sobre o Amazon Prime no BR:</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>- o valor t√° lindo</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               id           created_at  \\\n",
       "0  Tue Sep 10 13:52:02 +0000 2019  1171421071708426240   \n",
       "1  Tue Sep 10 13:52:04 +0000 2019  1171421083322527744   \n",
       "2  Tue Sep 10 13:52:04 +0000 2019  1171421083620249601   \n",
       "3   BT Sport minimum cost: ¬£30 pm                  NaN   \n",
       "4  Premier Sports cost: ¬£11.99 pm                  NaN   \n",
       "5       Amazon Prime cost: ¬£7.99‚Ä¶                  NaN   \n",
       "6  Tue Sep 10 13:52:06 +0000 2019  1171421088389062659   \n",
       "7  Tue Sep 10 13:52:08 +0000 2019  1171421096631046144   \n",
       "8  Tue Sep 10 13:52:08 +0000 2019  1171421099722252288   \n",
       "9              - o valor t√° lindo                  NaN   \n",
       "\n",
       "                                              id_str  \\\n",
       "0    ADEUS NETFLIX COM SEU CATALOGO DE FILMES LIXOSO   \n",
       "1                          Eu j√° tinha o Prime Video   \n",
       "2  RT @HLTCO: Sky Sports minimum cost: ¬£40 per month   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "5                                                NaN   \n",
       "6  RT @bonjurliana: indo assinar o amazon prime h...   \n",
       "7        Amazon prime por 10 conto com o prime v√≠deo   \n",
       "8     RT @milapellicer: Sobre o Amazon Prime no BR:    \n",
       "9                                                NaN   \n",
       "\n",
       "                                                text  \n",
       "0                                                NaN  \n",
       "1   alterei pra assinatura do Prime que vai sair ...  \n",
       "2                                                NaN  \n",
       "3                                                NaN  \n",
       "4                                                NaN  \n",
       "5                                                NaN  \n",
       "6                                                NaN  \n",
       "7   twitch prime e o servi√ßo de m√∫sica era tudo q...  \n",
       "8                                                NaN  \n",
       "9                                                NaN  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y1ciRVrDN-Pl"
   },
   "source": [
    "**Conta a quantidade de linhas de tweets neutros, positivos e negativos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mD7m9FBFN-Pm"
   },
   "outputs": [],
   "source": [
    "dataset[dataset.Classificacao=='Neutro'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pd1bopmPN-Po"
   },
   "outputs": [],
   "source": [
    "dataset[dataset.Classificacao=='Positivo'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BbQDdx6fN-Pr"
   },
   "outputs": [],
   "source": [
    "dataset[dataset.Classificacao=='Negativo'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TkZ7gTeJN-Pt"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "dataset.Classificacao.value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SCDmdHipN-Pv"
   },
   "outputs": [],
   "source": [
    "dataset.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kJFE0rWAN-Py"
   },
   "source": [
    "## Pre-Processamento dos Dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EvrKfzJQN-Pz"
   },
   "source": [
    "* Remove linhas duplicadas na base de dados\n",
    "    - Problema na coleta dos dados.\n",
    "* Remove Stopwords\n",
    "* Faz Stemming nos dados\n",
    "* Remove caracteres indesejados como links, pontua√ß√£o etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iiIbvZbwN-P0"
   },
   "outputs": [],
   "source": [
    "dataset.drop_duplicates(['Text'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9AJh2pkEN-P1"
   },
   "outputs": [],
   "source": [
    "dataset.Text.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Coh0XgGqN-P4"
   },
   "source": [
    "## ** Separando tweets e suas Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nMwzYhDFN-P4"
   },
   "outputs": [],
   "source": [
    "tweets = dataset['Text']\n",
    "classes = dataset['Classificacao']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y51tqO69N-P6"
   },
   "source": [
    "** Instala bibliotecas e baixa a base de dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mB2zdiTZN-P6"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('rslp')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7bAQswo_N-P8"
   },
   "source": [
    "**Fun√ß√µes de Pre-processamento de dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6VISYmqMN-P9"
   },
   "outputs": [],
   "source": [
    "def RemoveStopWords(instancia):\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    palavras = [i for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1R52LDb2N-QB"
   },
   "outputs": [],
   "source": [
    "def Stemming(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    palavras = []\n",
    "    for w in instancia.split():\n",
    "        palavras.append(stemmer.stem(w))\n",
    "    return (\" \".join(palavras))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s1L3Kfr-N-QE"
   },
   "outputs": [],
   "source": [
    "def Limpeza_dados(instancia):\n",
    "    # remove links, pontos, virgulas,ponto e virgulas dos tweets\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    return (instancia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lusLFKwZN-QI"
   },
   "source": [
    "** Entenda como funciona cada fun√ß√£o**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nDtlMpUmN-QI"
   },
   "outputs": [],
   "source": [
    "RemoveStopWords('Eu n√£o gosto do partido, e tamb√©m n√£o votaria novamente nesse governante!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JnrJKtZFN-QK"
   },
   "outputs": [],
   "source": [
    "Stemming('Eu n√£o gosto do partido, e tamb√©m n√£o votaria novamente nesse governante!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TFrAgPI9N-QL"
   },
   "outputs": [],
   "source": [
    "Limpeza_dados('Assita aqui o video do Governador falando sobre a CEMIG https://www.uol.com.br :) ;)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rFRbKWfFN-QO"
   },
   "source": [
    "** Aplica as 3 fun√ß√µes de Pre-processamento nos dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BAlu-RtDN-QP"
   },
   "outputs": [],
   "source": [
    "def Preprocessing(instancia):\n",
    "    stemmer = nltk.stem.RSLPStemmer()\n",
    "    instancia = re.sub(r\"http\\S+\", \"\", instancia).lower().replace('.','').replace(';','').replace('-','').replace(':','').replace(')','')\n",
    "    stopwords = set(nltk.corpus.stopwords.words('portuguese'))\n",
    "    palavras = [stemmer.stem(i) for i in instancia.split() if not i in stopwords]\n",
    "    return (\" \".join(palavras))\n",
    "\n",
    "# Aplica a fun√ß√£o em todos os dados:\n",
    "tweets = [Preprocessing(i) for i in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GpbDgdfEN-QR"
   },
   "outputs": [],
   "source": [
    "Preprocessing('Eu n√£o gosto do partido, e tamb√©m n√£o votaria novamente nesse governante. Assita o video aqui https:// :)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4Nr2nQYXN-QS"
   },
   "source": [
    "**Visualize os dados e veja como ficou ap√≥s o pr√©-processamento**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c04o1V3xN-QT"
   },
   "outputs": [],
   "source": [
    "tweets[:50]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "0kqSnklmN-QV"
   },
   "source": [
    "## Criando o modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OuEc376oN-QV"
   },
   "source": [
    "**Instancia o objeto que faz a vetoriza√ß√£o dos dados de texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7kPGn3G6N-QW"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(analyzer=\"word\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TL168-e0N-QY"
   },
   "source": [
    "**Aplica o vetorizador nos dados de texto**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z_OufE_5N-QY"
   },
   "outputs": [],
   "source": [
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "type(freq_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GzHXr2TNN-Qa"
   },
   "outputs": [],
   "source": [
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "S-vF1aDAN-Qd"
   },
   "source": [
    "**Formato (Linhas, Colunas) da matriz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LNuDjTH6N-Qe"
   },
   "outputs": [],
   "source": [
    "freq_tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "R1ANkhjhN-Qg"
   },
   "source": [
    "**Matriz**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g05OeGVCN-Qg"
   },
   "outputs": [],
   "source": [
    "freq_tweets.A"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MsWdPRkaN-Qj"
   },
   "source": [
    "** Testando o modelo com algumas inst√¢ncias simples**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oKswXL8TN-Qj"
   },
   "outputs": [],
   "source": [
    "# defina inst√¢ncias de teste dentro de uma lista\n",
    "testes = ['Esse governo est√° no in√≠cio, vamos ver o que vai dar',\n",
    "          'Estou muito feliz com o governo de Minas esse ano',\n",
    "          'O estado de Minas Gerais decretou calamidade financeira!!!',\n",
    "          'A seguran√ßa desse pa√≠s est√° deixando a desejar',\n",
    "          'O governador de Minas √© mais uma vez do PT']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "K5qgbrDPN-Qm"
   },
   "source": [
    "**Aplica a fun√ß√£o de Pr√©-processamento nos dados**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8rbcyd6wN-Qm"
   },
   "outputs": [],
   "source": [
    "testes = [Preprocessing(i) for i in testes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vh-MK_RBN-Qo"
   },
   "outputs": [],
   "source": [
    "# Transforma os dados de teste em vetores de palavras.\n",
    "freq_testes = vectorizer.transform(testes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rWwXiAsLN-Qp"
   },
   "outputs": [],
   "source": [
    "# Fazendo a classifica√ß√£o com o modelo treinado.\n",
    "for t, c in zip (testes,modelo.predict(freq_testes)):\n",
    "    print (t +\", \"+ c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "URzT5h0pN-Qr"
   },
   "outputs": [],
   "source": [
    "# Probabilidades de cada classe\n",
    "print (modelo.classes_)\n",
    "modelo.predict_proba(freq_testes).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OjrcFuYNN-Qv"
   },
   "source": [
    "## ** Fun√ß√£o de Tags de Nega√ß√µes**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hl7fpNi4N-Qw"
   },
   "source": [
    "* Acrescenta uma tag _NEG encontrada ap√≥s um 'n√£o'.\n",
    "* Objetivo √© dar mais peso para o modelo identificar uma invers√£o de sentimento da frase.\n",
    "* Exemplos: \n",
    "    - Eu gosto de cachorros, positivo.\n",
    "    - Eu **n√£o** gosto de cachorros, negativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "r0uWFI7CN-Qw"
   },
   "outputs": [],
   "source": [
    "def marque_negacao(texto):\n",
    "    negacoes = ['n√£o','not']\n",
    "    negacao_detectada = False\n",
    "    resultado = []\n",
    "    palavras = texto.split()\n",
    "    for p in palavras:\n",
    "        p = p.lower()\n",
    "        if negacao_detectada == True:\n",
    "            p = p + '_NEG'\n",
    "        if p in negacoes:\n",
    "            negacao_detectada = True\n",
    "        resultado.append(p)\n",
    "    return (\" \".join(resultado))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VnEGlbyQN-Q1"
   },
   "source": [
    "**Exemplos de utiliza√ß√£o da tag de nega√ß√µes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yZZNWh2YN-Q1"
   },
   "outputs": [],
   "source": [
    "marque_negacao('Eu gosto do partido, votaria novamente nesse governante!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-3XE8NMBN-Q3"
   },
   "outputs": [],
   "source": [
    "marque_negacao('Eu N√£o gosto do partido, e tamb√©m n√£o votaria novamente nesse governante!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DuMo0NyzN-Q6"
   },
   "source": [
    "## **Criando modelos com Pipelines**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QV9ZaTo4N-Q7"
   },
   "source": [
    "* Pipelines s√£o interessantes para reduzir c√≥digo e automatizar fluxos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E0W5gpr2N-Q7"
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OEqd6LpEN-Q-"
   },
   "outputs": [],
   "source": [
    "pipeline_simples = Pipeline([\n",
    "  ('counts', CountVectorizer()),\n",
    "  ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xx83-l2jN-RA"
   },
   "source": [
    "* Pipeline que atribui tag de negacoes nas palavras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QMja6f1_N-RA"
   },
   "outputs": [],
   "source": [
    "pipeline_negacoes = Pipeline([\n",
    "  ('counts', CountVectorizer(tokenizer=lambda text: marque_negacao(text))),\n",
    "  ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3s8IYnTqN-RB"
   },
   "outputs": [],
   "source": [
    "pipeline_simples.fit(tweets,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eEe_xi5RN-RF"
   },
   "outputs": [],
   "source": [
    "pipeline_simples.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zFtrsfPLN-RG"
   },
   "source": [
    "* Gera o modelo de nega√ß√µes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "D7qvoT9KN-RG"
   },
   "outputs": [],
   "source": [
    "pipeline_negacoes.fit(tweets,classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vb_16zLWN-RI"
   },
   "source": [
    "* Etapas do pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kxAXlTCZN-RI"
   },
   "outputs": [],
   "source": [
    "pipeline_negacoes.steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8uOrdLbpN-RL"
   },
   "source": [
    "## Validando os Modelos com Valida√ß√£o Cruzada"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "ZSO1TDjdN-RL"
   },
   "source": [
    "* Fazendo o cross validation do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cdzCoSkdN-RM"
   },
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(pipeline_simples, tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "6wrZIEfGN-RO"
   },
   "source": [
    "* Medindo a acur√°cia m√©dia do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YsqVrFdtN-RO"
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "5D32i6aKN-RS"
   },
   "source": [
    "* Medidas de valida√ß√£o do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9zxOQrd4N-RT"
   },
   "outputs": [],
   "source": [
    "sentimento=['Positivo','Negativo','Neutro']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qKfnnvw4N-RU"
   },
   "source": [
    "* Matriz de confus√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsrSrom-N-RW"
   },
   "outputs": [],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B0_8SCJ9N-RX"
   },
   "source": [
    "## **Modelo com a Tag de Nega√ß√µes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "g3l3iT9tN-RX"
   },
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(pipeline_negacoes, tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tE_1SUj-N-RZ"
   },
   "source": [
    "* Medindo a acur√°cia m√©dia do modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rQOijDH7N-RZ"
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RAuDaRzrN-Rb"
   },
   "outputs": [],
   "source": [
    "sentimento=['Positivo','Negativo','Neutro']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "collapsed": true,
    "id": "xdFPuGoEN-Rd"
   },
   "source": [
    "* Matriz de confus√£o"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Ka8d4A9N-Rd"
   },
   "outputs": [],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xjTqTnFiN-Rg"
   },
   "source": [
    "## ** Avaliando modelo com Bigrams**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pnp_Q6SkN-Rh"
   },
   "outputs": [],
   "source": [
    "'eu gosto', 'gosto do' , 'do brasil'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3P6z5RcXN-Ri"
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1,2))\n",
    "freq_tweets = vectorizer.fit_transform(tweets)\n",
    "modelo = MultinomialNB()\n",
    "modelo.fit(freq_tweets,classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xQk6Y-cwN-Rk"
   },
   "outputs": [],
   "source": [
    "resultados = cross_val_predict(modelo, freq_tweets, classes, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hXjpvOjqN-Rl"
   },
   "outputs": [],
   "source": [
    "metrics.accuracy_score(classes,resultados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "9j4l-8Y3N-Rn"
   },
   "outputs": [],
   "source": [
    "sentimento=['Positivo','Negativo','Neutro']\n",
    "print (metrics.classification_report(classes,resultados,sentimento))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0zTMXL2tN-Ro"
   },
   "outputs": [],
   "source": [
    "print (pd.crosstab(classes, resultados, rownames=['Real'], colnames=['Predito'], margins=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T8WkzVgIN-Rp"
   },
   "source": [
    "## ** Considera√ß√µes Finais**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "su1YgnZ1N-Rp"
   },
   "source": [
    "* Considere aumentar a quantidade de dados de treino.\n",
    "\n",
    "* Pela sua simplicidade o Naive Bayes pode ser usado perfeitamente como um algoritmo de Baseline.\n",
    "\n",
    "* Considere alterar os par√¢metros do algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jL2x-FrIN-Rq"
   },
   "source": [
    "**www.minerandodados.com.br** - *A maior comunidade de Data Science do Brasil*"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Classifica√ß√£o_tweets.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
